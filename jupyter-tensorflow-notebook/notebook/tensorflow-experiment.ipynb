{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2ef5f83b0ec5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_DOCUMENT_LENGTH = 100\n",
    "VOCAB_SIZE = 20000\n",
    "EMBEDDING_SIZE = 50\n",
    "N_FILTERS = 10\n",
    "N_CLASSES = 8\n",
    "WINDOW_SIZE=20\n",
    "FILTER_SHAPE1 = [WINDOW_SIZE,EMBEDDING_SIZE]\n",
    "FILTER_SHAPE2 = [WINDOW_SIZE,N_FILTERS] \n",
    "POOLING_WINDOW = 4\n",
    "POOLING_STRIDE = 2\n",
    "LEARNING_RATE = 0.05\n",
    "STEPS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 3 6 5 2 7 4]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/CS503/labeled_news.csv', header=None)\n",
    "X, y = df[1], df[0]\n",
    "y = y.apply(lambda x: x-1)\n",
    "print (y.unique())\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "x_train = tokenizer.texts_to_sequences(x_train)\n",
    "x_test = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=MAX_DOCUMENT_LENGTH)\n",
    "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test, maxlen=MAX_DOCUMENT_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn2_model(features, target):\n",
    "    target = tf.one_hot(target, N_CLASSES, 1, 0)\n",
    "    word_vectors = tf.contrib.layers.embed_sequence(features, vocab_size=VOCAB_SIZE, embed_dim=EMBEDDING_SIZE, scope='words')\n",
    "    word_vectors = tf.expand_dims(word_vectors, 3)\n",
    "    conv1 = tf.contrib.layers.convolution2d(word_vectors, N_FILTERS, FILTER_SHAPE1, padding='VALID')\n",
    "    pool1 = tf.nn.max_pool(conv1, ksize=[1, POOLING_WINDOW, 1, 1], strides=[1, POOLING_STRIDE, 1, 1], padding='SAME')\n",
    "    pool1 = tf.transpose(pool1, [0, 1, 3, 2])\n",
    "    conv2 = tf.contrib.layers.convolution2d(pool1, N_FILTERS, FILTER_SHAPE2, padding='VALID')\n",
    "    pool2 = tf.squeeze(tf.reduce_max(conv2, 1), squeeze_dims=[1])\n",
    "    logits = tf.contrib.layers.fully_connected(pool2, N_CLASSES, activation_fn=None)\n",
    "    loss = tf.contrib.losses.softmax_cross_entropy(logits, target)\n",
    "    \n",
    "    train_op = tf.contrib.layers.optimize_loss(\n",
    "          loss,\n",
    "          tf.contrib.framework.get_global_step(),\n",
    "          optimizer='Adam',\n",
    "          learning_rate=LEARNING_RATE)\n",
    "    \n",
    "    return ({\n",
    "          'class': tf.argmax(logits, 1),\n",
    "          'prob': tf.nn.softmax(logits)\n",
    "      }, loss, train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpe1ogt2vz\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7faffcf03eb8>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/tmpe1ogt2vz'}\n",
      "WARNING:tensorflow:From <ipython-input-5-6962e9277256>:3: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-5-6962e9277256>:3: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-4-46aad4758ad1>:11: softmax_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.softmax_cross_entropy instead. Note that the order of the logits and labels arguments has been changed.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:398: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:399: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.compute_weighted_loss instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:152: add_arg_scope.<locals>.func_with_args (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.add_loss instead.\n",
      "WARNING:tensorflow:From <ipython-input-4-46aad4758ad1>:15: get_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_global_step\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpe1ogt2vz/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.07937, step = 1\n",
      "INFO:tensorflow:global_step/sec: 3.84456\n",
      "INFO:tensorflow:loss = 0.812666, step = 101 (26.014 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 200 into /tmp/tmpe1ogt2vz/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.72258.\n",
      "WARNING:tensorflow:From <ipython-input-5-6962e9277256>:5: calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpe1ogt2vz/model.ckpt-200\n",
      "[1, 5, 5, 0, 5, 0, 5, 5, 0, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 1, 0, 0, 5, 5, 5, 5, 5, 0, 0, 0, 5, 0, 1, 5, 5, 5, 5, 5, 5, 0, 5, 0, 5, 0, 5, 0, 0, 5, 5, 5, 0, 5, 5, 5, 1, 5, 5, 0, 5, 5, 5, 5, 0, 0, 5, 5, 0, 5, 5, 0, 0, 5, 0, 0, 5, 5, 0, 5, 5, 0, 0, 0, 5, 1, 0, 5, 5, 0, 0, 5, 5, 0, 0, 0, 5, 5, 5, 5, 5, 0, 0, 0, 5, 0, 5, 5, 0, 0, 1, 5, 5, 5, 0, 5, 5, 1, 0, 0, 5, 5, 1, 5, 1, 0, 0, 0, 5, 5, 0, 0, 5, 0, 5, 5, 5, 5, 0, 0, 0, 5, 0, 5, 0, 0, 0, 0, 5, 0, 0, 5, 5, 5, 0, 0, 5, 5, 5, 5, 0, 5, 5, 0, 5, 5, 5, 5, 0, 5, 0]\n",
      "Accuracy: 0.292135\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.contrib.learn.Estimator(model_fn=cnn2_model)\n",
    "# Train and predict\n",
    "classifier.fit(x_train, y_train, steps=STEPS)\n",
    "# Evaluate model \n",
    "y_predicted = [p['class'] for p in classifier.predict(x_test, as_iterable=True)]\n",
    "print(y_predicted)\n",
    "# compare the predict label and true label\n",
    "score = metrics.accuracy_score(y_test, y_predicted) \n",
    "print('Accuracy: {0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/backend.py:1456: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/backend.py:1557: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/backend.py:1422: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 50)           1000000   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 51, 64)            160064    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 12, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               66000     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 808       \n",
      "=================================================================\n",
      "Total params: 1,226,872\n",
      "Trainable params: 1,226,872\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "360/360 [==============================]360/360 [==============================] - 1s 4ms/step - loss: 1.8276 - acc: 0.2583\n",
      "\n",
      "Epoch 2/3\n",
      "360/360 [==============================]360/360 [==============================] - 1s 2ms/step - loss: 1.7505 - acc: 0.2222\n",
      "\n",
      "Epoch 3/3\n",
      "360/360 [==============================]360/360 [==============================] - 1s 2ms/step - loss: 1.7144 - acc: 0.2611\n",
      "\n",
      "178/178 [==============================]178/178 [==============================] - 0s 1ms/step\n",
      "\n",
      "Test set\n",
      "  Loss: 1.629\n",
      "  Accuracy: 0.331\n"
     ]
    }
   ],
   "source": [
    "keras = tf.keras\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(VOCAB_SIZE, EMBEDDING_SIZE, input_length=MAX_DOCUMENT_LENGTH))\n",
    "model.add(keras.layers.Conv1D(64, EMBEDDING_SIZE, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(pool_size=4))\n",
    "model.add(keras.layers.LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(keras.layers.Dense(8, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(x_train, y_train, epochs=3)\n",
    "\n",
    "accr = model.evaluate(x_test,y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_directory = '../data/glove.6B'\n",
    "file_name = 'glove.6B.{}d.txt'\n",
    "\n",
    "def create_embed_dict(embed_file):\n",
    "    embed_dict = dict()\n",
    "    with open(embed_file) as file:\n",
    "        for line in file.readlines():\n",
    "            row = line.strip().split()\n",
    "            word = row[0]\n",
    "            embed_vect = [float(i) for i in row[1:]]\n",
    "            embed_dict[word] = embed_vect\n",
    "    return embed_dict\n",
    "\n",
    "def create_embed_matrix(embed_dict):\n",
    "    embed_matrix = np.zeros((VOCAB_SIZE, EMBEDDING_SIZE))\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        embed_vect = embed_dict.get(word, None)\n",
    "        if embed_vect is not None:\n",
    "            embed_matrix[index] = embed_vect\n",
    "        else:\n",
    "            print ('Not found:', word, embed_matrix[index])\n",
    "    \n",
    "    embed_matrix[0] = embed_dict['unk']\n",
    "    return embed_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def glove50d_cnn_model(features, target):\n",
    "    target = tf.one_hot(target, N_CLASSES, 1, 0)\n",
    "    embed_dict = create_embed_dict(data_directory + '/' + file_name.format(EMBEDDING_SIZE))\n",
    "    embed_matrix = create_embed_matrix(embed_dict)\n",
    "    embed_matrix = tf.cast(embed_matrix, tf.float32)\n",
    "    word_vectors = tf.nn.embedding_lookup(embed_matrix, features)\n",
    "    word_vectors = tf.expand_dims(word_vectors, 3)\n",
    "    conv1 = tf.contrib.layers.convolution2d(word_vectors, N_FILTERS, FILTER_SHAPE1, padding='VALID')\n",
    "    pool1 = tf.nn.max_pool(conv1, ksize=[1, POOLING_WINDOW, 1, 1], strides=[1, POOLING_STRIDE, 1, 1], padding='SAME')\n",
    "    pool1 = tf.transpose(pool1, [0, 1, 3, 2])\n",
    "    conv2 = tf.contrib.layers.convolution2d(pool1, N_FILTERS, FILTER_SHAPE2, padding='VALID')\n",
    "    pool2 = tf.squeeze(tf.reduce_max(conv2, 1), squeeze_dims=[1])\n",
    "    logits = tf.contrib.layers.fully_connected(pool2, N_CLASSES, activation_fn=None)\n",
    "    loss = tf.contrib.losses.softmax_cross_entropy(logits, target)\n",
    "    \n",
    "    train_op = tf.contrib.layers.optimize_loss(\n",
    "          loss,\n",
    "          tf.contrib.framework.get_global_step(),\n",
    "          optimizer='Adam',\n",
    "          learning_rate=LEARNING_RATE)\n",
    "    \n",
    "    return ({\n",
    "          'class': tf.argmax(logits, 1),\n",
    "          'prob': tf.nn.softmax(logits)\n",
    "      }, loss, train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpr2wp3425\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7faf903bfa90>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/tmpr2wp3425'}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpr2wp3425/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.04163, step = 1\n",
      "INFO:tensorflow:global_step/sec: 4.73515\n",
      "INFO:tensorflow:loss = 1.56044, step = 101 (21.119 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 200 into /tmp/tmpr2wp3425/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.36187.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpr2wp3425/model.ckpt-200\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 1, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 5, 0, 5, 0, 0, 0]\n",
      "Accuracy: 0.303371\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.contrib.learn.Estimator(model_fn=glove50d_cnn_model)\n",
    "# Train and predict\n",
    "classifier.fit(x_train, y_train, steps=STEPS)\n",
    "# Evaluate model \n",
    "y_predicted = [p['class'] for p in classifier.predict(x_test, as_iterable=True)]\n",
    "print(y_predicted)\n",
    "# compare the predict label and true label\n",
    "score = metrics.accuracy_score(y_test, y_predicted) \n",
    "print('Accuracy: {0:f}'.format(score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
